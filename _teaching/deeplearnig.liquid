---
layout: page
title: "CSE676 <br>Deep Learning"
description:
img: assets/img/Deep-learning.png
year: 2024
category: graduate
related_publications: false
toc:
    sidebar: right
back_link: '/teaching'
back_text: 'Courses Page'
enable_heading_styles: true

semesters:
  - value: "fall-2024"
    label: "Fall 2024"
    selected: true
---


  <!-- Course description -->
  <div class="course-description-box">
    <p>
      Deep Learning algorithms learn multi-level representations of data, with each level explaining the data in
      a hierarchical manner. Such algorithms have been effective at uncovering underlying structure in data,
      e.g., features to discriminate between classes. They have been successful in many artificial intelligence
      problems including image classification, speech recognition, and natural language processing.
    </p>
    <p>
      The course, which will be taught through lectures and projects, will cover the underlying theory, the range
      of applications to which it has been applied, and learning from very large data sets. The course will cover
      connectionist architectures commonly associated with deep learning, e.g., basic neural networks, convolutional
      neural networks, and recurrent neural networks. Methods to train and optimize the architectures and methods
      to perform effective inference with them will be the main focus. Students will be encouraged to use open-source
      software libraries such as PyTorch.
    </p>
    <p class="course-note">
      <strong>Pre-requisite:</strong>
      <a href="{{ '/teaching/machinelearning/' | relative_url }}">
        Introductory Machine Learning (ML)
      </a>.
      A course on Probabilistic Graphical Models (PGMs) is helpful but not necessary.
    </p>
  </div>

  <!-- Course Logistics -->
  <h2>Instructor Information</h2>
  <p><strong>Course Instructor</strong>: Jue Guo [C]</p>
  <ul>
    <li>
      <em>Research Area:</em>
      Optimization for machine learning, Adversarial Learning, Continual Learning, and Graph Learning
    </li>
    <li>
      Interested in participating in our research? Reach to me by
      <a href="mailto:jueguo@buffalo.edu">email</a>.
    </li>
  </ul>


<!-- Outline heading + short intro text -->
<div class="outline-top">
  <h2>Course Outline and Logistics</h2>
  <p>
    Check out the <a href="#lecture-notes">course material</a> under lecture notes.
  </p>
</div>

<!-- The semester-year selector snippet, placed just below the outline -->
<div class="semester-year-snippet">
  {% include semester-year-toggle.liquid semesters=page.semesters %}
</div>

<!-- Then your toggled blocks (course-info tables, etc.) below -->
<div class="outline-content">
  <!-- For example, "Fall 2024" partial -->
  <div data-semester-year="fall-2024" style="display: none;">
    {% include teaching/deep_learning/fall-2024.liquid %}
  </div>
  
  <!-- "Summer 2025" partial -->
  <div data-semester-year="summer-2025" style="display: none;">
  </div>

  <!-- "Spring 2026" partial -->
  <div data-semester-year="spring-2026" style="display: none;">
  </div>
</div>


<h3>Note on Logistics</h3>
<ul>
  <li>A week-ahead notice for mid-term, based on the pace of the course.</li>
  <li>The logistic is <span style="color:red;">subject to change</span> based on
      the overall pace and the performance of the class.</li>
</ul>

  <!-- Grading Section -->
<h2>Grading</h2>
<p>
  The following is the outline of the grading:
</p>

<h3>Grading Rubric</h3>
<p>
  This course is <strong>absolute</strong> grading, meaning no curve, as there is a certain standard we need to
  uphold for students to have a good knowledge of deep learning.
</p>

<table class="styled-table">
  <thead>
    <tr>
      <th>Percentage</th>
      <th>Letter Grade</th>
      <th>Percentage</th>
      <th>Letter Grade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>95-100</td><td>A</td>
      <td>70-74</td><td>C+</td>
    </tr>
    <tr>
      <td>90-94</td><td>A-</td>
      <td>65-69</td><td>C</td>
    </tr>
    <tr>
      <td>85-89</td><td>B+</td>
      <td>60-64</td><td>C-</td>
    </tr>
    <tr>
      <td>80-84</td><td>B</td>
      <td>55-59</td><td>D</td>
    </tr>
    <tr>
      <td>75-79</td><td>B-</td>
      <td>0-54</td><td>F</td>
    </tr>
  </tbody>
</table>

<!-- Lecture Notes -->
<h2 id="lecture-notes">Lecture Notes</h2>
<p>
  The notes are based on
  <a href="https://d2l.ai/" target="_blank">Dive into Deep Learning</a>.
  Throughout my teaching, I have noticed that students sometimes struggle with understanding the derivations in
  the textbook due to the omission of several steps. To address this, I have expanded the derivations and provided
  more detailed explanations.
</p>
<p>
  Below are the lecture notes. Please note that these notes are updated regularly, so be sure to check back often
  for the latest updates.
</p>

<table class="styled-table">
  <thead>
    <tr>
      <th>Topic</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Introduction</td>
      <td>
        <ul>
          <li>
            <a href="{{ 'assets/courses/deeplearning/week_1_2/introduction' | relative_url }}">
              Introduction, Preliminaries &amp; Linear Neural Network
            </a>
          </li>
          <li>
            <a href="{{ 'assets/courses/deeplearning/week_1_2/classification_convexity' | relative_url }}">
              Linear Neural Network for Classification &amp; Start of Optimization
            </a>
          </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>Optimization</td>
      <td>
        <ul>
          <li>
            <a href="{{ 'assets/courses/deeplearning/optimization/convexity_gd' | relative_url }}">
              Convexity &amp; Gradient Descent
            </a>
          </li>
          <li>
            <a href="{{ 'assets/courses/deeplearning/optimization/stochastic_gd' | relative_url }}">
              Stochastic Gradient Descent
            </a>
          </li>
          <li>
            <a href="{{ 'assets/courses/deeplearning/optimization/optimization_algorithms' | relative_url }}">
              Optimization Algorithms
            </a>
          </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>DNN and CNN</td>
      <td>
        <ul>
          <li>
            <a href="{{ 'assets/courses/deeplearning/cnn/dnn_cnn' | relative_url }}">
              DNN and CNNs
            </a>
          </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>RNN</td>
      <td>
        <ul>
          <li>
            <a href="{{ 'assets/courses/deeplearning/rnn/markov' | relative_url }}">
              Markov Models and \(n\)-gram
            </a>
          </li>
          <li>
            <a href="{{ 'assets/courses/deeplearning/rnn/vinilla_rnn' | relative_url }}">
              Recurrent Neural Networks
            </a>
          </li>
          <li>
            <a href="{{ 'assets/courses/deeplearning/rnn/modern_rnn' | relative_url }}">
              Modern Recurrent Neural Networks
            </a>
          </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td>GNN</td>
      <td>
        <ul>
          <li>
            <a href="{{ '/assets/courses/deeplearning/gnnpapers/grl' | relative_url }}">
              Graph Representation Learning
            </a>
          </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
